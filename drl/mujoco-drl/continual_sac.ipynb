{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a89a2f68",
   "metadata": {},
   "source": [
    "## Entorno `CRLPusherEnv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e9cdac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gymnasium.envs.mujoco.pusher_v5 import PusherEnv\n",
    "from gymnasium.spaces import Box\n",
    "\n",
    "\n",
    "class CRLPusherEnv(PusherEnv):\n",
    "    \"\"\"\n",
    "    Pusher con no-estacionariedad por material (dinamica + reward) para SAC.\n",
    "\n",
    "    reward = reward_base_material\n",
    "             + progress_weight * delta_dist_obj_goal\n",
    "             - stagnation_penalty (si hay contacto sin progreso)\n",
    "             + success_bonus (si alcanza el target)\n",
    "\n",
    "    Observacion = obs_pusher (23-dim) + one_hot(material) (2-dim) = 25-dim\n",
    "    \"\"\"\n",
    "\n",
    "    MATERIALS = {\n",
    "        \"rigid\": dict(\n",
    "            physics=dict(\n",
    "                damping_scale=1.0,\n",
    "                frictionloss_scale=1.0,\n",
    "                object_mass_scale=1.2,\n",
    "                object_sliding_friction_scale=1.1,\n",
    "            ),\n",
    "            reward=dict(\n",
    "                success_bonus=150.0,\n",
    "                success_threshold=0.07,\n",
    "                dist_weight=1.25,\n",
    "                near_weight=0.50,\n",
    "                control_weight=0.0,\n",
    "                progress_weight=50.0,\n",
    "                stagnation_penalty=0.30,\n",
    "                stagnation_contact_threshold=0.10,\n",
    "                stagnation_progress_tolerance=3e-4,\n",
    "            ),\n",
    "        ),\n",
    "        \"delicate\": dict(\n",
    "            physics=dict(\n",
    "                damping_scale=0.7,\n",
    "                frictionloss_scale=0.5,\n",
    "                object_mass_scale=0.5,\n",
    "                object_sliding_friction_scale=0.4,\n",
    "            ),\n",
    "            reward=dict(\n",
    "                success_bonus=150.0,        # antes 120\n",
    "                success_threshold=0.07,     # antes 0.05\n",
    "                dist_weight=1.15,\n",
    "                near_weight=0.40,           # antes 0.25\n",
    "                control_weight=0.0,         # antes 0.12\n",
    "                progress_weight=55.0,       # antes 35\n",
    "                stagnation_penalty=0.35,    # antes 0.25\n",
    "                stagnation_contact_threshold=0.10,  # antes 0.06\n",
    "                stagnation_progress_tolerance=3e-4,\n",
    "            ),\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.material = \"rigid\"\n",
    "        self.obj_body_id = self.model.body(\"object\").id\n",
    "        self.obj_geom_id = self.model.body_geomadr[self.obj_body_id]\n",
    "\n",
    "        # Fisica base\n",
    "        self._base_dof_damping = self.model.dof_damping.copy()\n",
    "        self._base_dof_frictionloss = self.model.dof_frictionloss.copy()\n",
    "        self._base_body_mass = self.model.body_mass.copy()\n",
    "        self._base_geom_friction = self.model.geom_friction.copy()\n",
    "\n",
    "        # Parametros de reward (se sobreescriben en set_material)\n",
    "        self.success_bonus = 150.0\n",
    "        self.success_threshold = 0.07\n",
    "        self.progress_weight = 50.0\n",
    "        self.stagnation_penalty = 0.30\n",
    "        self.stagnation_contact_threshold = 0.10\n",
    "        self.stagnation_progress_tolerance = 3e-4\n",
    "        self.episode_steps = 0\n",
    "        self._prev_obj_goal_dist = np.nan\n",
    "\n",
    "        # Extender observacion con one-hot(material) — 2 dims\n",
    "        base_low = self.observation_space.low\n",
    "        base_high = self.observation_space.high\n",
    "        self.observation_space = Box(\n",
    "            low=np.concatenate([base_low, np.zeros(2, dtype=base_low.dtype)]),\n",
    "            high=np.concatenate([base_high, np.ones(2, dtype=base_high.dtype)]),\n",
    "            dtype=base_low.dtype,\n",
    "        )\n",
    "        self.set_material(\"rigid\")\n",
    "\n",
    "    # Observaciones\n",
    "\n",
    "    def _material_one_hot(self):\n",
    "        idx = list(self.MATERIALS.keys()).index(self.material)\n",
    "        oh = np.zeros(len(self.MATERIALS), dtype=self.observation_space.dtype)\n",
    "        oh[idx] = 1.0\n",
    "        return oh\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return np.concatenate(\n",
    "            [super()._get_obs(), self._material_one_hot()]\n",
    "        ).astype(self.observation_space.dtype)\n",
    "\n",
    "    # Distancias\n",
    "\n",
    "    def _get_obj_goal_distance(self):\n",
    "        return float(np.linalg.norm(\n",
    "            self.get_body_com(\"object\") - self.get_body_com(\"goal\")\n",
    "        ))\n",
    "\n",
    "    def _get_tip_obj_distance(self):\n",
    "        return float(np.linalg.norm(\n",
    "            self.get_body_com(\"tips_arm\") - self.get_body_com(\"object\")\n",
    "        ))\n",
    "\n",
    "    # Fisica\n",
    "\n",
    "    def set_physics(self, *, damping_scale=1.0, frictionloss_scale=1.0,\n",
    "                    object_mass_scale=1.0, object_sliding_friction_scale=1.0):\n",
    "        self.model.dof_damping[:] = self._base_dof_damping * damping_scale\n",
    "        self.model.dof_frictionloss[:] = self._base_dof_frictionloss * frictionloss_scale\n",
    "\n",
    "        self.model.body_mass[:] = self._base_body_mass\n",
    "        self.model.body_mass[self.obj_body_id] = (\n",
    "            self._base_body_mass[self.obj_body_id] * object_mass_scale\n",
    "        )\n",
    "\n",
    "        self.model.geom_friction[:] = self._base_geom_friction\n",
    "        self.model.geom_friction[self.obj_geom_id, 0] = (\n",
    "            self._base_geom_friction[self.obj_geom_id, 0] * object_sliding_friction_scale\n",
    "        )\n",
    "\n",
    "    def set_material(self, name: str):\n",
    "        if name not in self.MATERIALS:\n",
    "            raise ValueError(f\"Material '{name}' no existe: {list(self.MATERIALS)}\")\n",
    "\n",
    "        cfg = self.MATERIALS[name]\n",
    "        self.set_physics(**cfg[\"physics\"])\n",
    "\n",
    "        rw = cfg[\"reward\"]\n",
    "        self.success_bonus = rw[\"success_bonus\"]\n",
    "        self.success_threshold = rw[\"success_threshold\"]\n",
    "        self.progress_weight = rw[\"progress_weight\"]\n",
    "        self.stagnation_penalty = rw[\"stagnation_penalty\"]\n",
    "        self.stagnation_contact_threshold = rw[\"stagnation_contact_threshold\"]\n",
    "        self.stagnation_progress_tolerance = rw[\"stagnation_progress_tolerance\"]\n",
    "\n",
    "        self.reward_dist_weight = rw[\"dist_weight\"]\n",
    "        self.reward_near_weight = rw[\"near_weight\"]\n",
    "        self.reward_control_weight = rw[\"control_weight\"]\n",
    "\n",
    "        self.material = name\n",
    "\n",
    "    # Reset\n",
    "\n",
    "    def reset(self, *, seed=None, options=None):\n",
    "        if options and \"material\" in options:\n",
    "            self.set_material(options[\"material\"])\n",
    "\n",
    "        obs, info = super().reset(seed=seed, options=options)\n",
    "        self.episode_steps = 0\n",
    "        self._prev_obj_goal_dist = self._get_obj_goal_distance()\n",
    "\n",
    "        obs = self._get_obs()\n",
    "        info[\"material\"] = self.material\n",
    "        info[\"distance_to_goal\"] = self._prev_obj_goal_dist\n",
    "        info[\"tip_to_object\"] = self._get_tip_obj_distance()\n",
    "        return obs, info\n",
    "\n",
    "    # Step\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, base_reward, terminated, truncated, info = super().step(action)\n",
    "        self.episode_steps += 1\n",
    "\n",
    "        obj_goal_dist = self._get_obj_goal_distance()\n",
    "        tip_obj_dist = self._get_tip_obj_distance()\n",
    "\n",
    "        prev_dist = self._prev_obj_goal_dist if np.isfinite(self._prev_obj_goal_dist) else obj_goal_dist\n",
    "        progress = prev_dist - obj_goal_dist\n",
    "\n",
    "        is_success = obj_goal_dist <= self.success_threshold\n",
    "\n",
    "        is_stagnating = (\n",
    "            tip_obj_dist <= self.stagnation_contact_threshold\n",
    "            and obj_goal_dist > self.success_threshold\n",
    "            and progress <= self.stagnation_progress_tolerance\n",
    "        )\n",
    "        stagnation_cost = self.stagnation_penalty if is_stagnating else 0.0\n",
    "\n",
    "        reward_progress = self.progress_weight * progress\n",
    "        reward = base_reward + reward_progress - stagnation_cost\n",
    "        if is_success:\n",
    "            reward += self.success_bonus\n",
    "            terminated = True\n",
    "\n",
    "        self._prev_obj_goal_dist = obj_goal_dist\n",
    "\n",
    "        obs = self._get_obs()\n",
    "        info.update({\n",
    "            \"material\": self.material,\n",
    "            \"distance_to_goal\": obj_goal_dist,\n",
    "            \"tip_to_object\": tip_obj_dist,\n",
    "            \"distance_progress\": float(progress),\n",
    "            \"is_success\": float(is_success),\n",
    "            \"episode_steps\": self.episode_steps,\n",
    "            \"reward_base\": float(base_reward),\n",
    "            \"reward_progress\": float(reward_progress),\n",
    "            \"stagnation_cost\": float(stagnation_cost),\n",
    "        })\n",
    "        return obs, reward, terminated, truncated, info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b206a9",
   "metadata": {},
   "source": [
    "## Hiperparámetros SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc9fa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os, shutil, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium as gym\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.callbacks import BaseCallback, CallbackList\n",
    "import torch as th\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "# Configuracion general\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "\n",
    "LOG_DIR = \"./logs/pusher_crl_sac\"\n",
    "MAX_EPISODE_STEPS = 200\n",
    "TOTAL_STEPS = 1_500_000\n",
    "\n",
    "\n",
    "EXPERIMENT_MODE = \"baseline\"\n",
    "\n",
    "if os.path.exists(LOG_DIR):\n",
    "    shutil.rmtree(LOG_DIR)\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "\n",
    "if EXPERIMENT_MODE == \"baseline\":\n",
    "    SCHEDULE = [(0, \"rigid\")]\n",
    "elif EXPERIMENT_MODE == \"non_stationary\":\n",
    "    SCHEDULE = [\n",
    "        (0, \"rigid\"),\n",
    "        (250_000, \"delicate\"),\n",
    "        (500_000, \"rigid\"),\n",
    "        (750_000, \"delicate\"),\n",
    "    ]\n",
    "else:\n",
    "    raise ValueError(\"EXPERIMENT_MODE debe ser 'baseline' o 'non_stationary'\")\n",
    "\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "# Callbacks\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "\n",
    "class NonStationaryMaterialCallback(BaseCallback):\n",
    "    \"\"\"Cambia material segun un schedule en timesteps.\"\"\"\n",
    "\n",
    "    def __init__(self, schedule, verbose=1):\n",
    "        super().__init__(verbose)\n",
    "        self.schedule = sorted(schedule, key=lambda x: x[0])\n",
    "        self._next_idx = 0\n",
    "        self.applied_changes = []\n",
    "\n",
    "    def _apply_material(self, t_step, material):\n",
    "        self.training_env.env_method(\"set_material\", material)\n",
    "        self.applied_changes.append((int(t_step), material))\n",
    "        if self.verbose:\n",
    "            bar = \"=\" * 60\n",
    "            print(f\"\\n{bar}\\n  [CAMBIO MATERIAL] t={t_step:,} -> {material}\\n{bar}\\n\")\n",
    "\n",
    "    def _on_training_start(self) -> None:\n",
    "        while (\n",
    "            self._next_idx < len(self.schedule)\n",
    "            and self.schedule[self._next_idx][0] <= 0\n",
    "        ):\n",
    "            t_step, material = self.schedule[self._next_idx]\n",
    "            self._apply_material(t_step, material)\n",
    "            self._next_idx += 1\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        while (\n",
    "            self._next_idx < len(self.schedule)\n",
    "            and self.num_timesteps >= self.schedule[self._next_idx][0]\n",
    "        ):\n",
    "            _, material = self.schedule[self._next_idx]\n",
    "            self._apply_material(self.num_timesteps, material)\n",
    "            self._next_idx += 1\n",
    "        return True\n",
    "\n",
    "\n",
    "class LivePlotCallback(BaseCallback):\n",
    "    \"\"\"Graficas en vivo + heartbeat durante el entrenamiento SAC.\"\"\"\n",
    "\n",
    "    def __init__(self, plot_freq=20_000, heartbeat_freq=5_000,\n",
    "                 total_steps=1_000_000, verbose=1):\n",
    "        super().__init__(verbose)\n",
    "        self.plot_freq = plot_freq\n",
    "        self.heartbeat_freq = heartbeat_freq\n",
    "        self.total_steps = total_steps\n",
    "        self.last_plot_step = 0\n",
    "        self.last_hb_step = 0\n",
    "\n",
    "        self.ts = []\n",
    "        self.returns = []\n",
    "        self.success_rates = []\n",
    "        self.final_distances = []\n",
    "        self.alphas = []\n",
    "\n",
    "        self._successes = []\n",
    "        self._final_dists = []\n",
    "        self.material_changes = []\n",
    "\n",
    "    def _read_alpha(self):\n",
    "        # Compatible con diferentes versiones/configuraciones de SAC en SB3\n",
    "        try:\n",
    "            log_ent_coef = getattr(self.model, \"log_ent_coef\", None)\n",
    "            if log_ent_coef is not None:\n",
    "                if isinstance(log_ent_coef, th.Tensor):\n",
    "                    return float(th.exp(log_ent_coef.detach()).mean().cpu().item())\n",
    "                return float(np.exp(float(log_ent_coef)))\n",
    "\n",
    "            ent_coef_tensor = getattr(self.model, \"ent_coef_tensor\", None)\n",
    "            if ent_coef_tensor is not None:\n",
    "                if isinstance(ent_coef_tensor, th.Tensor):\n",
    "                    return float(ent_coef_tensor.detach().mean().cpu().item())\n",
    "                return float(ent_coef_tensor)\n",
    "\n",
    "            ent_coef = getattr(self.model, \"ent_coef\", None)\n",
    "            if isinstance(ent_coef, (int, float)):\n",
    "                return float(ent_coef)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        return float(\"nan\")\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        dones = self.locals.get(\"dones\", [])\n",
    "        infos = self.locals.get(\"infos\", [])\n",
    "\n",
    "        for done, info in zip(dones, infos):\n",
    "            if not done:\n",
    "                continue\n",
    "            ti = info.get(\"terminal_info\", info)\n",
    "            self._successes.append(float(ti.get(\"is_success\", 0.0)))\n",
    "            d = ti.get(\"distance_to_goal\", np.nan)\n",
    "            if not np.isnan(d):\n",
    "                self._final_dists.append(float(d))\n",
    "\n",
    "        # Heartbeat\n",
    "        if (self.num_timesteps - self.last_hb_step) >= self.heartbeat_freq:\n",
    "            self.last_hb_step = self.num_timesteps\n",
    "            pct = 100.0 * self.num_timesteps / self.total_steps\n",
    "            sr = np.mean(self._successes[-50:]) if self._successes else 0.0\n",
    "            md = np.mean(self._final_dists[-50:]) if self._final_dists else np.nan\n",
    "            alpha_val = self._read_alpha()\n",
    "            try:\n",
    "                mat = self.training_env.get_attr(\"material\")[0]\n",
    "            except Exception:\n",
    "                mat = \"?\"\n",
    "            print(\n",
    "                f\"  [{pct:5.1f}%] t={self.num_timesteps:>8,}  \"\n",
    "                f\"sr={sr:.2f}  dist={md:.3f}  alpha={alpha_val:.5f}  material={mat}\"\n",
    "            )\n",
    "\n",
    "        if (self.num_timesteps - self.last_plot_step) < self.plot_freq:\n",
    "            return True\n",
    "        self.last_plot_step = self.num_timesteps\n",
    "\n",
    "        if not self.model.ep_info_buffer:\n",
    "            return True\n",
    "\n",
    "        mean_r = float(np.mean([e[\"r\"] for e in self.model.ep_info_buffer]))\n",
    "        sr = np.mean(self._successes[-100:]) if self._successes else 0.0\n",
    "        mfd = np.mean(self._final_dists[-100:]) if self._final_dists else np.nan\n",
    "        alpha_val = self._read_alpha()\n",
    "\n",
    "        self.ts.append(self.num_timesteps)\n",
    "        self.returns.append(mean_r)\n",
    "        self.success_rates.append(float(sr))\n",
    "        self.final_distances.append(float(mfd))\n",
    "        self.alphas.append(alpha_val)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        fig, axes = plt.subplots(1, 4, figsize=(20, 4))\n",
    "\n",
    "        axes[0].plot(self.ts, self.returns, \"o-\", ms=3)\n",
    "        axes[0].set_title(\"Rolling mean return\")\n",
    "        axes[0].set_ylabel(\"return\")\n",
    "\n",
    "        axes[1].plot(self.ts, self.success_rates, \"o-\", ms=3, color=\"green\")\n",
    "        axes[1].set_title(\"Success rate (ult. 100 eps)\")\n",
    "        axes[1].set_ylim(-0.05, 1.05)\n",
    "\n",
    "        axes[2].plot(self.ts, self.final_distances, \"o-\", ms=3, color=\"red\")\n",
    "        axes[2].set_title(\"Mean final distance\")\n",
    "        axes[2].set_ylabel(\"distance\")\n",
    "\n",
    "        alpha_arr = np.asarray(self.alphas, dtype=float)\n",
    "        if np.isfinite(alpha_arr).any():\n",
    "            axes[3].plot(self.ts, self.alphas, \"o-\", ms=3, color=\"darkorange\")\n",
    "        else:\n",
    "            axes[3].text(0.5, 0.5, \"alpha sin datos\", ha=\"center\", va=\"center\")\n",
    "        axes[3].set_title(\"Entropia alpha (SAC)\")\n",
    "        axes[3].set_ylabel(\"alpha\")\n",
    "\n",
    "        for ax in axes:\n",
    "            ax.set_xlabel(\"timesteps\")\n",
    "            for ts_c, mat_c in self.material_changes:\n",
    "                ax.axvline(\n",
    "                    ts_c,\n",
    "                    ls=\"--\",\n",
    "                    alpha=0.5,\n",
    "                    color=\"red\" if mat_c == \"delicate\" else \"blue\",\n",
    "                )\n",
    "            ax.grid(alpha=0.3)\n",
    "\n",
    "        try:\n",
    "            mat = self.training_env.get_attr(\"material\")[0]\n",
    "        except Exception:\n",
    "            mat = \"?\"\n",
    "        pct = 100.0 * self.num_timesteps / self.total_steps\n",
    "        fig.suptitle(\n",
    "            f\"SAC - CRLPusherEnv  [{pct:.0f}%]  |  material: {mat}  |  \"\n",
    "            f\"return: {mean_r:.1f}  success: {sr:.2f}  alpha: {alpha_val:.5f}\"\n",
    "        )\n",
    "        plt.tight_layout()\n",
    "        display(fig)\n",
    "        plt.close(fig)\n",
    "        return True\n",
    "\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "# Crear entornos\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "\n",
    "def make_env(material=\"rigid\", log_path=None):\n",
    "    env = CRLPusherEnv()\n",
    "    env = gym.wrappers.TimeLimit(env, max_episode_steps=MAX_EPISODE_STEPS)\n",
    "    info_kw = (\n",
    "        \"is_success\", \"distance_to_goal\", \"tip_to_object\",\n",
    "        \"distance_progress\", \"episode_steps\", \"material\",\n",
    "        \"reward_base\", \"reward_progress\", \"stagnation_cost\",\n",
    "    )\n",
    "    env = Monitor(env, log_path or LOG_DIR, info_keywords=info_kw)\n",
    "    env.reset(options={\"material\": material})\n",
    "    return env\n",
    "\n",
    "\n",
    "train_env = make_env(\"rigid\")\n",
    "eval_env = make_env(\"rigid\", log_path=os.path.join(LOG_DIR, \"eval\"))\n",
    "\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "# Modelo SAC\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "\n",
    "model = SAC(\n",
    "    \"MlpPolicy\",\n",
    "    train_env,\n",
    "    verbose=0,\n",
    "    tensorboard_log=os.path.join(LOG_DIR, \"tb\"),\n",
    "\n",
    "    learning_rate=3e-4,\n",
    "    batch_size=256,\n",
    "    gamma=0.99,\n",
    "    tau=0.005,\n",
    "\n",
    "    buffer_size=500_000,      \n",
    "    learning_starts=10_000,\n",
    "\n",
    "    train_freq=1,\n",
    "    gradient_steps=2,\n",
    "\n",
    "    ent_coef=\"auto\",\n",
    "    target_entropy=\"auto\",\n",
    "\n",
    "    policy_kwargs=dict(\n",
    "    net_arch=[256, 256],\n",
    "    ),\n",
    "\n",
    "    device=\"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c57990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════\n",
    "# Evaluación antes del entrenamiento\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "\n",
    "def evaluate(model, env, material, n_episodes=20):\n",
    "    successes, rets, dists = 0, [], []\n",
    "    for _ in range(n_episodes):\n",
    "        obs, _ = env.reset(options={\"material\": material})\n",
    "        done, ep_ret, last = False, 0.0, {}\n",
    "        while not done:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, r, term, trunc, last = env.step(action)\n",
    "            done = term or trunc\n",
    "            ep_ret += r\n",
    "        rets.append(ep_ret)\n",
    "        dists.append(last.get(\"distance_to_goal\", np.nan))\n",
    "        if last.get(\"is_success\", 0.0) > 0.5:\n",
    "            successes += 1\n",
    "    return dict(\n",
    "        mean_return=float(np.mean(rets)),\n",
    "        success_rate=successes / n_episodes,\n",
    "        mean_dist=float(np.nanmean(dists)),\n",
    "    )\n",
    "\n",
    "\n",
    "for mat in [\"rigid\", \"delicate\"]:\n",
    "    res = evaluate(model, eval_env, mat, n_episodes=5)\n",
    "    print(f\"  [{mat:>8s}]  return={res['mean_return']:.2f}  \"\n",
    "          f\"success={res['success_rate']:.2f}  dist={res['mean_dist']:.4f}\")\n",
    "print()\n",
    "\n",
    "\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "# Entrenamiento SAC con schedule no-estacionario\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "\n",
    "switch_cb = NonStationaryMaterialCallback(SCHEDULE, verbose=1)\n",
    "plot_cb   = LivePlotCallback(\n",
    "    plot_freq=15_000,\n",
    "    heartbeat_freq=5_000,\n",
    "    total_steps=TOTAL_STEPS,\n",
    ")\n",
    "\n",
    "class _LinkCallbacks(BaseCallback):\n",
    "    \"\"\"Propaga los cambios de material al plot en vivo.\"\"\"\n",
    "    def __init__(self, switch_cb, plot_cb):\n",
    "        super().__init__(verbose=0)\n",
    "        self._switch = switch_cb\n",
    "        self._plot   = plot_cb\n",
    "        self._seen   = 0\n",
    "    def _on_step(self) -> bool:\n",
    "        n = len(self._switch.applied_changes)\n",
    "        if n > self._seen:\n",
    "            for c in self._switch.applied_changes[self._seen:]:\n",
    "                self._plot.material_changes.append(c)\n",
    "            self._seen = n\n",
    "        return True\n",
    "\n",
    "link_cb   = _LinkCallbacks(switch_cb, plot_cb)\n",
    "callbacks = CallbackList([switch_cb, link_cb, plot_cb])\n",
    "\n",
    "print(f\"Iniciando entrenamiento SAC: {TOTAL_STEPS:,} steps\")\n",
    "print(f\"Schedule: {SCHEDULE}\\n\")\n",
    "\n",
    "t0 = time.time()\n",
    "model.learn(total_timesteps=TOTAL_STEPS, callback=callbacks, progress_bar=False)\n",
    "elapsed = time.time() - t0\n",
    "print(f\"\\n✓ Entrenamiento completado en {elapsed/60:.1f} min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b67bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════\n",
    "# (Opcional) Visualización en ventana MuJoCo\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "import time\n",
    "\n",
    "env_vis = CRLPusherEnv(render_mode=\"human\")\n",
    "\n",
    "for material in [\"rigid\", \"delicate\"]:\n",
    "    print(f\"\\n{'='*40}  material = {material}\")\n",
    "    obs, _ = env_vis.reset(options={\"material\": material})\n",
    "    successes, episodes = 0, 0\n",
    "\n",
    "    for step in range(3000):\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, terminated, truncated, info = env_vis.step(action)\n",
    "        time.sleep(1 / 30)\n",
    "        if terminated or truncated:\n",
    "            episodes += 1\n",
    "            if info.get(\"is_success\", 0.0) > 0.5:\n",
    "                successes += 1\n",
    "            obs, _ = env_vis.reset(options={\"material\": material})\n",
    "\n",
    "    sr = successes / max(episodes, 1)\n",
    "    print(f\"  Episodes={episodes}  Successes={successes}  Rate={sr:.2f}\")\n",
    "\n",
    "env_vis.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ce6d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint guardado: ./logs/pusher_crl_sac/checkpoints/sac_pusher_baseline_1000000_steps.zip\n",
      "Replay buffer guardado: ./logs/pusher_crl_sac/checkpoints/sac_pusher_baseline_1000000_steps_replay_buffer.pkl\n"
     ]
    }
   ],
   "source": [
    "# ═══════════════════════════════════════════════════════════════════\n",
    "# Guardar checkpoint final (inferencia + reanudar entrenamiento)\n",
    "# ═══════════════════════════════════════════════════════════════════\n",
    "\n",
    "CHECKPOINT_DIR = os.path.join(LOG_DIR, \"checkpoints\")\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "checkpoint_name = f\"sac_pusher_{EXPERIMENT_MODE}_{TOTAL_STEPS}_steps\"\n",
    "checkpoint_path = os.path.join(CHECKPOINT_DIR, checkpoint_name)\n",
    "replay_buffer_path = checkpoint_path + \"_replay_buffer.pkl\"\n",
    "\n",
    "model.save(checkpoint_path)\n",
    "model.save_replay_buffer(replay_buffer_path)\n",
    "\n",
    "print(f\"Checkpoint guardado: {checkpoint_path}.zip\")\n",
    "print(f\"Replay buffer guardado: {replay_buffer_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed6d1650",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'logs/pusher_crl_sac/checkpoints/sac_pusher_baseline_1000000_steps.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Carga para inferencia\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m inference_model = \u001b[43mSAC\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mModelo de inferencia cargado correctamente.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Carga para continuar entrenamiento\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Escritorio/extra/misis/.venv/lib/python3.12/site-packages/stable_baselines3/common/base_class.py:681\u001b[39m, in \u001b[36mBaseAlgorithm.load\u001b[39m\u001b[34m(cls, path, env, device, custom_objects, print_system_info, force_reset, **kwargs)\u001b[39m\n\u001b[32m    678\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m== CURRENT SYSTEM INFO ==\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    679\u001b[39m     get_system_info()\n\u001b[32m--> \u001b[39m\u001b[32m681\u001b[39m data, params, pytorch_variables = \u001b[43mload_from_zip_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_system_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_system_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mNo data found in the saved file\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    689\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mNo params found in the saved file\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Escritorio/extra/misis/.venv/lib/python3.12/site-packages/stable_baselines3/common/save_util.py:403\u001b[39m, in \u001b[36mload_from_zip_file\u001b[39m\u001b[34m(load_path, load_data, custom_objects, device, verbose, print_system_info)\u001b[39m\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_from_zip_file\u001b[39m(\n\u001b[32m    377\u001b[39m     load_path: Union[\u001b[38;5;28mstr\u001b[39m, pathlib.Path, io.BufferedIOBase],\n\u001b[32m    378\u001b[39m     load_data: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    382\u001b[39m     print_system_info: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    383\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[Optional[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]], TensorDict, Optional[TensorDict]]:\n\u001b[32m    384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    385\u001b[39m \u001b[33;03m    Load model data from a .zip archive\u001b[39;00m\n\u001b[32m    386\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    401\u001b[39m \u001b[33;03m        and dict of pytorch variables\u001b[39;00m\n\u001b[32m    402\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m     file = \u001b[43mopen_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mzip\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    405\u001b[39m     \u001b[38;5;66;03m# set device to cpu if cuda is not available\u001b[39;00m\n\u001b[32m    406\u001b[39m     device = get_device(device=device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/functools.py:909\u001b[39m, in \u001b[36msingledispatch.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    905\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[32m    906\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires at least \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    907\u001b[39m                     \u001b[33m'\u001b[39m\u001b[33m1 positional argument\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m909\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Escritorio/extra/misis/.venv/lib/python3.12/site-packages/stable_baselines3/common/save_util.py:240\u001b[39m, in \u001b[36mopen_path_str\u001b[39m\u001b[34m(path, mode, verbose, suffix)\u001b[39m\n\u001b[32m    225\u001b[39m \u001b[38;5;129m@open_path\u001b[39m.register(\u001b[38;5;28mstr\u001b[39m)\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mopen_path_str\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m, mode: \u001b[38;5;28mstr\u001b[39m, verbose: \u001b[38;5;28mint\u001b[39m = \u001b[32m0\u001b[39m, suffix: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m) -> io.BufferedIOBase:\n\u001b[32m    227\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    228\u001b[39m \u001b[33;03m    Open a path given by a string. If writing to the path, the function ensures\u001b[39;00m\n\u001b[32m    229\u001b[39m \u001b[33;03m    that the path exists.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    238\u001b[39m \u001b[33;03m    :return:\u001b[39;00m\n\u001b[32m    239\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopen_path_pathlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpathlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Escritorio/extra/misis/.venv/lib/python3.12/site-packages/stable_baselines3/common/save_util.py:291\u001b[39m, in \u001b[36mopen_path_pathlib\u001b[39m\u001b[34m(path, mode, verbose, suffix)\u001b[39m\n\u001b[32m    285\u001b[39m         path.parent.mkdir(exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m, parents=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    287\u001b[39m \u001b[38;5;66;03m# if opening was successful uses the open_path() function\u001b[39;00m\n\u001b[32m    288\u001b[39m \u001b[38;5;66;03m# if opening failed with IsADirectory|FileNotFound, calls open_path_pathlib\u001b[39;00m\n\u001b[32m    289\u001b[39m \u001b[38;5;66;03m#   with corrections\u001b[39;00m\n\u001b[32m    290\u001b[39m \u001b[38;5;66;03m# if reading failed with FileNotFoundError, calls open_path_pathlib with suffix\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopen_path_pathlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Escritorio/extra/misis/.venv/lib/python3.12/site-packages/stable_baselines3/common/save_util.py:272\u001b[39m, in \u001b[36mopen_path_pathlib\u001b[39m\u001b[34m(path, mode, verbose, suffix)\u001b[39m\n\u001b[32m    270\u001b[39m             path, suffix = newpath, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    271\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Escritorio/extra/misis/.venv/lib/python3.12/site-packages/stable_baselines3/common/save_util.py:264\u001b[39m, in \u001b[36mopen_path_pathlib\u001b[39m\u001b[34m(path, mode, verbose, suffix)\u001b[39m\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    263\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m open_path(\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m, mode, verbose, suffix)\n\u001b[32m    265\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m    266\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m suffix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m suffix != \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/pathlib.py:1015\u001b[39m, in \u001b[36mPath.open\u001b[39m\u001b[34m(self, mode, buffering, encoding, errors, newline)\u001b[39m\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1014\u001b[39m     encoding = io.text_encoding(encoding)\n\u001b[32m-> \u001b[39m\u001b[32m1015\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'logs/pusher_crl_sac/checkpoints/sac_pusher_baseline_1000000_steps.zip'"
     ]
    }
   ],
   "source": [
    "# Carga para inferencia\n",
    "inference_model = SAC.load(checkpoint_path, device=\"cpu\")\n",
    "print(\"Modelo de inferencia cargado correctamente.\")\n",
    "\n",
    "# Carga para continuar entrenamiento\n",
    "resume_env = make_env(\"rigid\", log_path=os.path.join(LOG_DIR, \"resume\"))\n",
    "resume_model = SAC.load(checkpoint_path, env=resume_env, device=\"cpu\")\n",
    "if os.path.exists(replay_buffer_path):\n",
    "    resume_model.load_replay_buffer(replay_buffer_path)\n",
    "print(\"Modelo listo para continuar entrenamiento.\")\n",
    "\n",
    "# Para ver heartbeat + charts en vivo al reanudar,\n",
    "# hay que crear de nuevo los callbacks y pasarlos a learn().\n",
    "RESUME_EXTRA_STEPS = 200_000\n",
    "\n",
    "resume_switch_cb = NonStationaryMaterialCallback(SCHEDULE, verbose=1)\n",
    "resume_plot_cb = LivePlotCallback(\n",
    "    plot_freq=15_000,\n",
    "    heartbeat_freq=5_000,\n",
    "    total_steps=resume_model.num_timesteps + RESUME_EXTRA_STEPS,\n",
    ")\n",
    "resume_link_cb = _LinkCallbacks(resume_switch_cb, resume_plot_cb)\n",
    "resume_callbacks = CallbackList([resume_switch_cb, resume_link_cb, resume_plot_cb])\n",
    "\n",
    "print(f\"Reanudando entrenamiento por {RESUME_EXTRA_STEPS:,} steps...\")\n",
    "resume_model.learn(\n",
    "    total_timesteps=RESUME_EXTRA_STEPS,\n",
    "    callback=resume_callbacks,\n",
    "    progress_bar=False,\n",
    "    reset_num_timesteps=False,\n",
    ")\n",
    "print(\"Resume completado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a4edf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
